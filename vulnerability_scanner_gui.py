import requests
from urllib.parse import urlencode, urljoin, urlparse
import tkinter as tk
from tkinter import messagebox, filedialog, scrolledtext, ttk
import json
import threading
from bs4 import BeautifulSoup

# Function to crawl web pages up to a given depth
def web_crawler(base_url, max_depth, callback):
    visited = set()
    to_visit = [(base_url, 0)]  # List of URLs to visit along with their depth
    discovered_urls = []

    while to_visit:
        url, depth = to_visit.pop(0)
        if url in visited or depth > max_depth:
            continue

        try:
            response = requests.get(url)
            soup = BeautifulSoup(response.text, 'html.parser')
            visited.add(url)
            discovered_urls.append(url)
            
            # Call the callback to update the GUI with the newly discovered URL
            callback(url)

            if depth < max_depth:
                for link in soup.find_all('a', href=True):
                    full_url = urljoin(base_url, link['href'])
                    parsed_url = urlparse(full_url)
                    if parsed_url.netloc == urlparse(base_url).netloc and full_url not in visited:
                        to_visit.append((full_url, depth + 1))

        except requests.exceptions.RequestException:
            pass

    return discovered_urls

# Function to scan for SQL Injection
def scan_sql_injection(url):
    payloads = ["' OR '1'='1", "' OR 'a'='a", "1' AND SLEEP(5)-- ", "' UNION SELECT NULL, NULL -- "]
    results = []

    for payload in payloads:
        full_url = f"{url}?{urlencode({'input': payload})}"
        try:
            response = requests.get(full_url)
            if any(error in response.text for error in ["syntax error", "mysql_fetch", "You have an error in your SQL syntax"]):
                results.append(f"Potential SQL Injection detected with payload: {payload}")
            if response.elapsed.total_seconds() > 5:
                results.append(f"Potential Time-based Blind SQL Injection detected with payload: {payload}")
        except requests.exceptions.RequestException:
            pass
    return results

# Function to scan for XSS
def scan_xss(url):
    payloads = [
        '<script>alert(1)</script>',
        '"><script>alert(1)</script>',
        '<img src=x onerror=alert(1)>',
        '<svg onload=alert(1)>',
        '<body/onload=alert(1)>',
        '<iframe src="javascript:alert(1)">'
    ]
    results = []

    for payload in payloads:
        full_url = f"{url}?{urlencode({'input': payload})}"
        try:
            response = requests.get(full_url)
            if payload in response.text:
                results.append(f"Potential XSS detected with payload: {payload}")
        except requests.exceptions.RequestException:
            pass

    return results

# Function to check for insecure headers
def check_insecure_headers(url):
    try:
        response = requests.get(url)
        headers = response.headers
        insecure_headers = []

        required_headers = {
            "Content-Security-Policy": "Not Present",
            "X-Frame-Options": "Not Present",
            "X-XSS-Protection": "Not Present",
            "Strict-Transport-Security": "Not Present",
            "Referrer-Policy": "Not Present",
            "Permissions-Policy": "Not Present",
            "Expect-CT": "Not Present",
            "Cache-Control": "Not Present"
        }

        for header, status in required_headers.items():
            if header not in headers:
                insecure_headers.append(f"Missing security header: {header}")
            else:
                if header == "Content-Security-Policy" and "unsafe-inline" in headers[header]:
                    insecure_headers.append(f"Insecure Content-Security-Policy header: {headers[header]}")
                if header == "X-Frame-Options" and headers[header] not in ["DENY", "SAMEORIGIN"]:
                    insecure_headers.append(f"Insecure X-Frame-Options header: {headers[header]}")

        return insecure_headers
    except requests.exceptions.RequestException:
        return []

# Function to run all checks
def run_scan(url, max_depth, update_callback):
    results = {}

    # Crawl the website
    discovered_urls = web_crawler(url, max_depth, update_callback)
    total_urls = len(discovered_urls)
    
    # Scan each discovered URL
    for i, target_url in enumerate(discovered_urls):
        # SQL Injection Scan
        sql_injection_results = scan_sql_injection(target_url)
        results[target_url] = {'SQL Injection': sql_injection_results}

        # XSS Scan
        xss_results = scan_xss(target_url)
        results[target_url]['XSS'] = xss_results

        # Insecure Headers Check
        insecure_headers_results = check_insecure_headers(target_url)
        results[target_url]['Insecure Headers'] = insecure_headers_results

        # Update progress bar
        progress_percentage = ((i + 1) / total_urls) * 100
        progress_bar['value'] = progress_percentage
        root.update_idletasks()

    return results

# Function to start scan from GUI
def start_scan():
    url = url_entry.get()
    depth = int(depth_entry.get())
    if url:
        progress_bar['value'] = 0
        scan_button.config(state=tk.DISABLED)
        status_label.config(text="Crawling and Scanning... Please wait.", fg="blue")
        save_button.pack_forget()  # Hide the save button until scan is complete
        threading.Thread(target=run_scan_with_progress, args=(url, depth)).start()
    else:
        messagebox.showwarning("Input Error", "Please enter a URL")

# Function to run scan with progress
def run_scan_with_progress(url, max_depth):
    def update_callback(new_url):
        results_text.insert(tk.END, f"Discovered URL: {new_url}\n", "discovered")
        results_text.yview(tk.END)  # Auto-scroll to the bottom

    results = run_scan(url, max_depth, update_callback)

    progress_bar['value'] = 100  # Scanning complete
    root.update_idletasks()

    # Display Results
    display_results(results)
    scan_button.config(state=tk.NORMAL)
    status_label.config(text="Scan Complete", fg="green")
    save_button.pack(pady=10)  # Show the save button after scan completion

# Function to display results in the text box
def display_results(scan_results):
    results_text.delete(1.0, tk.END)
    for url, vulnerabilities in scan_results.items():
        results_text.insert(tk.END, f"\n\nScanning Results for: {url}\n", "heading")
        for category, findings in vulnerabilities.items():
            results_text.insert(tk.END, f"\n{category} Results:\n", "subheading")
            if findings:
                for finding in findings:
                    results_text.insert(tk.END, f"- {finding}\n", "result")
            else:
                results_text.insert(tk.END, "No vulnerabilities found.\n", "safe")

# Function to save results to a file
def save_results():
    file_path = filedialog.asksaveasfilename(defaultextension=".txt",
                                             filetypes=[("Text Files", "*.txt"), ("All Files", "*.*")])
    if file_path:
        with open(file_path, 'w') as file:
            file.write(results_text.get(1.0, tk.END))
        messagebox.showinfo("Success", "Results saved successfully")

# Create the main GUI window
root = tk.Tk()
root.title("Vulnerability Scanner")
root.geometry("800x700")
root.configure(bg="#f5f5f5")

# URL Entry
url_label = tk.Label(root, text="Target URL:", font=("Arial", 12), bg="#f5f5f5")
url_label.pack(pady=10)
url_entry = tk.Entry(root, width=50, font=("Arial", 10))
url_entry.pack(pady=5)

# Depth Entry
depth_label = tk.Label(root, text="Crawl Depth (e.g., 3):", font=("Arial", 12), bg="#f5f5f5")
depth_label.pack(pady=10)
depth_entry = tk.Entry(root, width=10, font=("Arial", 10))
depth_entry.pack(pady=5)

# Scan Button
scan_button = tk.Button(root, text="Start Scan", command=start_scan, font=("Arial", 12), bg="#4CAF50", fg="white", relief="raised")
scan_button.pack(pady=10)

# Progress Bar
progress_bar = ttk.Progressbar(root, orient='horizontal', length=400, mode='determinate')
progress_bar.pack(pady=10)

# Status Label
status_label = tk.Label(root, text="", font=("Arial", 10), bg="#f5f5f5")
status_label.pack(pady=5)

# Results Display
results_text = scrolledtext.ScrolledText(root, width=90, height=25, font=("Courier", 10), bg="#e8e8e8", fg="#333333")
results_text.tag_config("heading", font=("Arial", 12, "bold"), foreground="#d9534f")
results_text.tag_config("subheading", font=("Arial", 11, "bold"), foreground="#5bc0de")
results_text.tag_config("result", font=("Arial", 10), foreground="#5bc0de")
results_text.tag_config("safe", font=("Arial", 10), foreground="#5cb85c")
results_text.tag_config("discovered", font=("Arial", 10), foreground="#f0ad4e")
results_text.pack(pady=10)

# Save Button (initially hidden)
save_button = tk.Button(root, text="Save Results", command=save_results, font=("Arial", 12), bg="#337ab7", fg="white", relief="raised")

# Run the GUI loop
root.mainloop()
